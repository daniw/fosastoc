\section{Aufgabe 3}
In der Vorlesung haben wir gesehen, wie man die Erfolgswahrscheinlichkeit
$\pi$ einer Binomialverteilung mit der Maximum-Likelihood-Methode schätzen 
kann, wenn man die Anzahl Versuche und die Anzahl Gewinne kennt. In dieser 
Aufgabe kombinieren wir mehrere solcher Beobachtungen zu einer Schätzung.
Angenommen Sie gehen über den Jahrmarkt und kaufen bei einer Losbude 30 Lose. 
Unter den 30 Losen sind 2 Gewinne. Am nächsten Tag erzählt Ihnen Ihr 
Studienkollege, dass er am Vorabend bei der gleichen Losbude 50 Lose gekauft
hat und darunter 4 Gewinne hatte. Wie kombinieren Sie die beiden Ergebnisse, 
um mit der Maximum-Likelihood-Methode eine möglichst gute Schätzung der 
Erfolgswahrscheinlichkeit zu erhalten?

\begin{enumerate}[(a)]
\item Sei $X_1$ die Zufallsvariable, die die Anzahl Gewinne unter 30 Losen 
beschreibt (``Ihre Gewinne''). Wenn wir annehmen, dass jedes Los 
unabhängig von jedem anderen Los ein Gewinn oder eine Niete ist, dann folgt
$X$ einer Binomialverteilung mit $n_1 = 30$ und unbekanntem Erfolgsparameter
$\pi$. Abgekürzt schreiben wir: $X_1 \sim Bin(n_1,\pi)$.
Analog sei $X_2$ die Zufallsvariable, die die Gewinne Ihres Kollegen 
beschreibt: $X_2 \sim Bin(n_2,\pi)$ mit $n_2=50$ und dem gleichen Wert für
die Erfolgswahrscheinlichkeit wie bei $X_1$.
Angenommen, die Anzahl Gewinne, die Sie gezogen haben, ist unabhängig von der
Anzahl Gewinne, die Ihr Kollege gezogen hat.
Wie lässt sich dann $P(X_1=x_1 \cap X_2=x_2)$ schreiben?
\item Wie lässt sich $log(P(X_1=x_1 \cap X_2=x_2))$ schreiben?
Versuchen Die diesen Term in eine Summe mit mehreren Termen umzuschreiben.
Welche Terme hängen von $\pi$ ab und welche nicht?
\item Der Maximum-Likelihood-Schätzer für $\pi$ ist derjenige Zahlenwert,
der, wenn man ihn anstelle von $\pi$ einsetzt, den grösstmöglichen Wert für
$log(P(X_1=x_1 \cap X_2=x_2))$ (oder $P(X_1=x_1 \cap X_2=x_2)$ das ist egal,
weil die Funktion $log$ monoton ist) liefert.
Finden Sie duch Ableiten und gleich Null setzen den Wert von $\pi$ in 
Abhängigkeit von $n_1, n_2, x_1$ und $x_2$ der $log(P(X_1=x_1 \cap X_2=x_2))$
maximiert.
\end{enumerate}


\subsection*{Allgemeines}
Was wissen wir? Nun, wir wissen, dass wir eine Binominalverteilung haben
und nehmen mal vorerst die Schätzung mittels der ``Momentenmethode'' an. 
\[X_1 \sim \text{Bin}(n_1=30, \widehat{\pi_1})$ 
  wobei $\widehat{\pi_1} = \frac{2}{30}\]
Zudem haben wir eine weitere Binominalveteilung durch unseren Kollegen mit
den vier Gewinnen.
\[X_2 \sim \text{Bin}(n_2=50, \widehat{\pi_2})$ 
  wobei $\widehat{\pi_2} = \frac{4}{50}\]
Mit der sog. ``Maximum-Likelihood'' Methode ist die Abschätzung der
Variable $\widehat{\pi}$ nicht ganz so einfach. Bei dieser Methode geht
es darum eine (eigentlich beliebige) Anzhal von möglichen Werten von 
$\widehat{\pi}$ zu verlgeichen und den ``passendsten'' Wert zu finden.
Um dies für alle möglichen Werte zu tun kann der folgende Ausdruck aufgestellt
werden.
\[  P[X=x] = {n \choose x} \cdot \pi^x \cdot (1-n)^{n-x} \]
$n$ steht hier für die Anzahl gekaufter Loose und $x$ für die Gewinne.
Um nun auf $\pi$ zu gelangen, muss die Ableitung dieses Ausdrucks zu Null
gleichgesetzt werden und natürlich nach $\pi$ aufgelöst werden.
Falls der Ausdruck kompliziert und mühsam zum Ableiten ist, kann versucht 
werden über eine \emph{Trick} zur Lösung zu gelangen. Der Trick basiert
darauf, dass jedes Extremum der Funktion $f(x)$ auch ein Extremum der 
Fuktion $\log(f(x))$ ist.
\[ \log\left(P[X=x]\right) = 
   \log\left({n \choose x} \cdot \pi^x \cdot (1-n)^{n-x}\right) \]
Der eignetliche Trick besteht darin, aus den Faktoren Summen zu bilden.
Diese können dann einzeln und unabhängig abgeleitet werden. Das ist natürlich
angenehmer zum Ableiten.
\[ 0 \stackrel{!}{=} \frac{d}{d\pi} \log\left( {n \choose x} \right) +
   x \cdot \log( \pi ) + (n-x)\cdot \log(1-\pi) \]
Wenn wir dies nun auflösen nach $\pi$ erhalten wir
\[ \pi = \frac{x}{n} \]
Dies stellt einen einfachen Fall dar in welchem das Ergebnis für $\pi$
mit dem übereinstimmt, welches man für die Momnetenmethode erhalten würde.

\subsection*{a)}
Die Anzahl Gewinne ist unabhängig und wird beschrieben durch
\[ P(X_1 = x_1 \cap X_2 = x_2 ) \]
was wie immer durch die Multiplikation der beiden Wahrscheinlichkeiten
entsteht.

\subsection*{b)}
\[ P(X_1 = x_1 \cap X_2 = x_2 ) =  P(X_1 = x_1) \cdot P(X_2=x_2)\]
\[ \log(P(X_1=x_1 \cap X_2=x_2)) = \log( P(X_1 = x_1) \cdot P(X_2=x_2)) \]
\[ \log(P(X_1=x_1 \cap X_2=x_2)) = \log( P(X_1 = x_1)) + \log(P(X_2=x_2)) \]

\[ = \log\left({n_1 \choose x_1} \cdot \pi^{x_1} \cdot (1-\pi)^{n_1-x_1}\right)
   + \log\left({n_2 \choose x_2} \cdot \pi^{x_2} \cdot (1-\pi)^{n_2-x_2}\right)   \]

\[ = \log\left( {n_1 \choose x_1} \right) + x_1 \cdot log(\pi) +
     (n_1-x_1) \cdot \log(1-\pi) \]
\[ + \log\left( {n_2 \choose x_2} \right) + x_2 \cdot log(\pi) +
     (n_2-x_2) \cdot \log(1-\pi) \]
Nun kann man sehen, dass $\pi$ nicht in allen Termen der Summe vorkommnt.

\subsection*{c)}
Der ermittelte Ausdruk bei 2-b) kann nun abgeleitet, gleich Null gesetzt
und nach $\pi$ aufgelöst werden.
\[ 0 \stackrel{!}{=} 0 + \frac{x_1}{\pi} + \frac{n_1-x_1}{\pi-1}
   + 0 + \frac{x_2}{\pi} + \frac{n_2-x_2}{\pi-1} \]
\[ 0 \stackrel{!}{=} \frac{x_1+x_2}{\pi} + \frac{(n_1-x_1)+(n_2-x_2)}{\pi-1} \]
\emph{Habe gerade keine Ahnung wie weiter rechnen \ldots}


