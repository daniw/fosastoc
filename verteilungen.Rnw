% coding:utf-8

%FOSASTOC, a LaTeX-Code for a electrical summary of stochastic
%Copyright (C) 2013, Daniel Winz, Ervin Mazlagic

%This program is free software; you can redistribute it and/or
%modify it under the terms of the GNU General Public License
%as published by the Free Software Foundation; either version 2
%of the License, or (at your option) any later version.

%This program is distributed in the hope that it will be useful,
%but WITHOUT ANY WARRANTY; without even the implied warranty of
%MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%GNU General Public License for more details.
%----------------------------------------

\chapter{Diskrete Verteilungen}
Diskrete Verteilungen beschreiben Probleme, welche
Ergebnisse aus $\mathbb{N}$ liefern und binär sind.

\paragraph{Binär}
Binär bedeutet, dass ein Ereignis zwei Werte annehmen kann. Bekannte
Beispiele binärer Probleme sind
\begin{itemize}
	\item Gewinnlose \hfill{} (\emph{Gewinn, Zonk})
	\item Münzwurf \hfill{} (\emph{Kopf, Zahl})
	\item Telefon \hfill{} (\emph{klingelt, klingelt nicht})
\end{itemize}
Viele nicht-binäre Probleme können aber leicht in binäre gewandelt
werden. Beispielsweise liefert ein Sensor analoge Signale, diese sind
$\notin \mathbb{N}$ noch sind diese binär. 
Dennoch kann man das Signal binär
untersuchen mit der Fragestellung 
"`\emph{Ist der Wert grösser als $xy$?}"'.
Diese Frage kann semantisch nur mit \emph{Ja} und \emph{Nein} beantwortet
werden und beschreibt somit ein binäres Problem. Die Zahl der Antworten
kann wiederum nur $\in \mathbb{N}$ sein. Somit sind die Bedingungen 
für ein binäres Problem gegeben.

\newpage
\section{Hypergeometrische Verteilung}
Die hypergeometrische Verteilung entspricht dem Urnenmodell:
\begin{itemize}
	\item Urne hat $r$ rote (postive) und $s$ schwarze (negative)
		Kugeln
		\[ r,s \in \mathbb{N} \]
	\item Die Menge der roten als auch der schwarzen Kugeln ist fix 
		\[ r,s \neq \infty \]
	\item Ein erzieltes Ergebnis reduziert die entsprechende Menge
		(\emph{Ziehen ohne Zurücklegen})
		\[ r \rightarrow  R - 1\]
\end{itemize}

\subsection{Verteilungsfunktion}
\[  
	X \sim Hyp(n,r,s)
\]

\[ \begin{array}{c l}
	n & \text{Anzahl Ziehungen} \\
	r & \text{Anzhal roter Kugeln (positive Ereignisse)} \\
	s & \text{Anzahl blauer Kugeln (negative Ereignisse)} \\
	N & \text{Anzahl Kugeln in der Urne } (N=r+s)
\end{array} \]

\[
	P(X=k)
		= \frac{\displaystyle 
			\binom{r}{k} \cdot \binom{s}{n-k}}{
				\displaystyle \binom{r+s}{n}}
		= \frac{\displaystyle 
			\binom{r}{k} \cdot \binom{N-r}{n-k}}{
				\displaystyle \binom{N}{n}}
\]

\subsection{Erwartungswert}

\[ 
	E(X) = n \cdot \frac{r}{N}, \qquad X \sim Hyp(n,r,s)
\]

\subsection{Varianz}

\[  
	Var(X) = n \cdot \frac{r}{N} \cdot 
		\left(1 - \frac{r}{N} \right)
		\cdot \frac{N-n}{N-1}, \qquad X \sim Hyp(n,r,s)
\]

\subsection{Verwendung in R}
\lstinline{R} stellt grundsätzlich vier Funktionen für die 
hypergeometrische Verteilung zur Verfügung. 
\begin{itemize}
	\item \lstinline{dhyper()} \hfill{} 
		(\emph{Wahrscheinlichkeitsverteilung})
	\item \lstinline{phyper()} \hfill{}
		(\emph{kumulative Wahrscheinlichkeit})
	\item \lstinline{qhyper()} \hfill{}
		(\emph{Verteilung der Quantile})
	\item \lstinline{rhyper()} \hfill{}
		(\emph{Zufallszahlen})
\end{itemize}
Die Abbildung \ref{fig:hyper} zeigt jeweils einen Plot zu den gegebenen
Funktionen aus \lstinline{R}. Für weitere Informationen zu Plots siehe
Kapitel \ref{sec:plots}.

<<dhyper, fig=FALSE, echo=FALSE>>=
plot(dhyper(x=c(1:100), m=100, n=100, k=100), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(x)', xlab='Wert x', 
     main='dhyper()')
@

<<phyper, fig=FALSE, echo=FALSE>>=
plot(phyper(q=c(1:100), m=100, n=100, k=100), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(X<=x)', xlab='Wert x', 
     main='phyper()')
@

<<qhyper, fig=FALSE, echo=FALSE>>=
plot(qhyper(p=seq(from=0, to=1, by=0.001), m=100, n=100, k=100), type='l',
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='Wert x', 
     xlab='Quantil in Promille', main='qhyper()')
@

<<rhyper, fig=FALSE, echo=FALSE>>=
plot(rhyper(nn=100, m=100, n=100, k=100), cex.lab=1.5, cex.axis=1.5, 
     cex.main=1.5, cex.sub=1.5, ylab='Wert x', xlab='x-te Zahl', 
     main='rhyper()')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<dhyper>>
@
\caption{Wahrscheinlichkeitsverteilung}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<phyper>>
@
\caption{kumulative Wahrscheinlichkeit}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<qhyper>>
@
\caption{Quantile}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<rhyper>>
@
\caption{Zufallszahlen}
\end{subfigure}
\caption{Hypergeometrische Verteilung ($m=100, n=100, k=100$)}
\label{fig:hyper}
\end{figure}

\clearpage

\subsection{Beispiel einer hypogeometrischen Verteilung}
Ein Beispiel aus dem Alltag ist die Teambildung im Mannschaftssport.
Ein Turnverein hat $9$ männliche und $17$ weibliche Mitglieder. Für ein
Fussballmatch gegen einen anderen Verein muss nun ein Team mit $11$
Mitgliedern gebildet werden. Wie wahrscheinlich ist es, dass das
Team aus einer bestimmten Anzahl Männern oder Frauen besteht?
\paragraph{Berechnung in R}
<<fig=FALSE>>=
man <- 9; women <- 17; player <- 11
boys <- dhyper(x=c(1:player), m=man, n=women, k=player)
girls <- dhyper(x=(1:player), m=women, n=man, k=player)
plot(boys, type='h')
plot(girls, type='h')
@
<<boys, fig=FALSE, echo=FALSE>>=
man <- 9; women <- 17; player <- 11
boys <- dhyper(x=c(1:player), m=man, n=women, k=player)
girls <- dhyper(x=(1:player), m=women, n=man, k=player)
plot(boys, type='h', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='', main='Männer')
@
<<girls, fig=FALSE, echo=FALSE>>=
man <- 9; women <- 17; player <- 11
boys <- dhyper(x=c(1:player), m=man, n=women, k=player)
girls <- dhyper(x=(1:player), m=women, n=man, k=player)
plot(girls, type='h', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='', main='Frauen')
@
\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<boys>>
@
\caption{$P(x)$ der Männer im Team}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
\centering
<<fig=TRUE, echo=FALSE>>=
<<girls>>
@
\caption{$P(x)$ der Frauen im Team}
\end{subfigure}
\caption{Teambildung nach Geschlecht}
\label{fig:team}
\end{figure}

\noindent
Die Plots aus der Abbildung \ref{fig:team} zeigen, dass es mit der 
höchsten Wahrscheinlichkeit
4 Männer und 7 Frauen im Team hat, was die gewünschte Anzahl von Spielern
ergibt für das Team ($4+7=11$). 

\clearpage
\newpage
\section{Binomialverteilung}
Die Binomialverteilung ist eine Verteilung, welche bei binären Problemen
auftritt wobei ein erzieltes Ergebnis nicht die weiteren Ergebnisse
beeinflusst. Sie ist somit ein Grenzfall der hypergeometrischen 
Verteilung (nämlich dann, wenn es sehr viele rote und schwarze 
Kugeln gibt).
\[ 
	\lim_{r,s \rightarrow \infty} Hyp(n,r,s) 
	\quad \Rightarrow \quad Bin(n,p)
\]

\subsection{Verteilungsfunktion}

\[ 
	X \sim Bin(n,p)
\]

\[ \begin{array}{c l} 
	n & \text{Anzahl Versuche} \\
	p & \text{Trefferwahrscheinlichkeit}
\end{array} \]

\[ \begin{array}{l c l} 
	P(X=x)
		&= 
		& \displaystyle \binom{n}{x} \cdot p^x 
			\cdot (1-p)^{n-x} \\
	& & \\
		&= 
		& \frac{\displaystyle n!}{\displaystyle x!\, (n-x)!} 
			\cdot p^x \cdot (1-p)^{n-x}
\end{array} \]

\subsection{Erwartungswert}

\[  
	E(X) = n \cdot p, \qquad X \sim Bin(n,p)
\]


\subsection{Varianz}

\[  
	Var(X) = n \cdot p \cdot (1-p), \qquad X \sim Bin(n,p)
\]

\subsection{Verwendung in R}
\lstinline{R} stellt grundsätzlich vier Funktionen für die 
Binomialverteilung zur Verfügung. 
\begin{itemize}
	\item \lstinline{dbinom()} \hfill{} 
		(\emph{Wahrscheinlichkeitsverteilung})
	\item \lstinline{pbinom()} \hfill{}
		(\emph{kumulative Wahrscheinlichkeit})
	\item \lstinline{qbinom()} \hfill{}
		(\emph{Verteilung der Quantile})
	\item \lstinline{rbinom()} \hfill{}
		(\emph{Zufallszahlen})
\end{itemize}
Die Abbildung \ref{fig:binom} zeigt jeweils einen Plot zu den gegebenen
Funktionen aus \lstinline{R}. Für weitere Informationen zu Plots siehe
Kapitel \ref{sec:plots}.

<<dbinom, fig=FALSE, echo=FALSE>>=
plot(dbinom(x=c(1:100), size=100, prob=0.5), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(x)', xlab='Wert x', 
     main='dbinom()')
@

<<pbinom, fig=FALSE, echo=FALSE>>=
plot(pbinom(q=c(1:100), size=100, prob=0.5), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(X<=x)', xlab='Wert x', 
     main='pbinom()')
@

<<qbinom, fig=FALSE, echo=FALSE>>=
plot(qbinom(p=seq(from=0, to=1, by=0.001), size=100, prob=0.5), type='l',
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='Wert x', 
     xlab='Quantil in Promille', main='qbinom()')
@

<<rbinom, fig=FALSE, echo=FALSE>>=
plot(rbinom(n=100, size=100, prob=0.5), cex.lab=1.5, cex.axis=1.5, 
     cex.main=1.5, cex.sub=1.5, ylab='Wert x', xlab='x-te Zahl', 
     main='rbinom()')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<dbinom>>
@
\caption{Wahrscheinlichkeitsverteilung}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<pbinom>>
@
\caption{kumulative Wahrscheinlichkeit}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<qbinom>>
@
\caption{Quantile}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<rbinom>>
@
\caption{Zufallszahlen}
\end{subfigure}
\caption{Binomialverteilung ($n=100, p=0.5$)}
\label{fig:binom}
\end{figure}

\subsection{Beispiel einer binomialen Verteilung}
Jemand sagt Ihnen, dass er von 100 Münzwürfen 80 mal Kopf erhielt.
Sie antworten spontan, dass Sie ihm 15 Treffer von 20 Versuchen ja 
noch geglaubt hätten aber nicht 80 von 100. 
Wie wahrscheinlich sind aber diese beiden Ergebnisse wenn Kopf 
und Zahl jeweils gleichwahrscheinliche Ergebnisse sind?

<<fig=FALSE>>=
plot(dbinom(x=c(1:100), size=100, prob=0.5), type='h')
plot(dbinom(x=c(1:20), size=20, prob=0.5), type='h')
@
<<coin1, fig=FALSE, echo=FALSE>>=
plot(dbinom(x=c(1:100), size=100, prob=0.5), type='h', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='', main='100 mal Münzwurf')
@
<<coin2, fig=FALSE, echo=FALSE>>=
plot(dbinom(x=c(1:20), size=20, prob=0.5), type='h', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='', main='20 mal Münzwurf')
@


\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<coin1>>
@
\caption{Verteilung für 100 Versuche}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<coin2>>
@
\caption{Verteilung für 20 Versuche}
\end{subfigure}
\caption{Wahrscheinlichkeitsverteilung beim Münzwurf}
\end{figure}

\clearpage
\newpage
\section{Poissonverteilung}

\subsection{Verwendung in R}
\lstinline{R} stellt grundsätzlich vier Funktionen für die 
Poissonverteilung zur Verfügung. 
\begin{itemize}
	\item \lstinline{dpois()} \hfill{} 
		(\emph{Wahrscheinlichkeitsverteilung})
	\item \lstinline{pois()} \hfill{}
		(\emph{kumulative Wahrscheinlichkeit})
	\item \lstinline{qpois()} \hfill{}
		(\emph{Verteilung der Quantile})
	\item \lstinline{rpois()} \hfill{}
		(\emph{Zufallszahlen})
\end{itemize}

<<dpois, fig=FALSE, echo=FALSE>>=
plot(dpois(x=c(1:100), lambda=50), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='P(x)', xlab='Wert x', 
     main='dpois()')
@

<<ppois, fig=FALSE, echo=FALSE>>=
plot(ppois(q=c(1:100), lambda=50), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='P(X<=x)', 
     xlab='Wert x', main='ppois()')
@

<<qpois, fig=FALSE, echo=FALSE>>=
plot(qpois(p=seq(from=0, to=1, by=0.001), lambda=50), type='l',
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='Wert x', 
     xlab='Quantil in Promille', main='qpois()')
@

<<rpois, fig=FALSE, echo=FALSE>>=
plot(rpois(n=100, lambda=50), cex.lab=1.5, cex.axis=1.5, 
     cex.main=1.5, cex.sub=1.5, ylab='Wert x', xlab='x-te Zahl', 
     main='rpois()')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<dpois>>
@
\caption{Wahrscheinlichkeitsverteilung}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<ppois>>
@
\caption{kumulative Wahrscheinlichkeit}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<qpois>>
@
\caption{Quantile}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<rpois>>
@
\caption{Zufallszahlen}
\end{subfigure}
\caption{Poissonverteilung ($\lambda=50$)}
\end{figure}

\clearpage

\section{Erwartungswert}
Der Erwartungswert einer diskreten Verteilung gibt jene Zahl an,
welche die Zufallsvariable im \emph{Mittel} annimmt. Sie beschreibt
quasi den mittleren Wert der Verteilung.

Für diskrete Wahrscheinlichkeitsverteilungen gilt, dass der 
Erwartungswert der Summe von Produkten aus Wahrscheinlichkeit und
Wert der Zufallsvariable entspricht. 
\[ \mu = E(X) = \sum x \cdot P(X=x) \]
$P(X=x)$ bedeutet \emph{Wahrscheinlichkeit, dass die Zufallsvariable $X$ 
genau $x$ ist}.


\section{Varianz}
Die Varianz einer Wahrscheinlichkeitsverteilung gibt ein Mass an für 
die Streuung der Warscheinlichkeiten um den Erwartungswert.

Die Varianz wird analog zum Erwartungswert ermittelt, wobei der Wert
der Zufallsvariable $x$ ersetzt wird durch das Quadrat der Abweichung
von Zufallsvariable und Erwartungswert $(x-\mu)^2$
\[ \begin{array}{l c l}
	Var(X) 
		& = 
		& E(X-\mu)^2 \\
	& &  \\
	Var(X)
		& = 
		& \sum \left( (x-\mu)^2 \cdot P(X=x) \right)
\end{array} \]

\section{Standardabweichung}
Die Standardabweichung einer Wahrscheinlichkeitsverteilung 
ist wie die Varianz ein Mass für die Streuung. Sie 
wird anhand der Varianz ermittelt mit dem Zusammenhang, dass die 
Standardabweichung der Quadratwurzel der Varianz entspricht.
\[ \begin{array}{l c l} 
	\sigma 
		& = 
		& \sqrt{Var(X)} \\
	& & \\
	\sigma
		& =
		& \sqrt{E(X-\mu)^2} \\
	& & \\
	\sigma
		& =
		& \sqrt{\sum \left( (x-\mu)^2 \cdot P(X=x) \right)}
\end{array} \]

\section{Zusammenfassung}

\subsection{Erwartungswert und Varianz}

\begin{table}[h!]
	\centering
	\begin{tabular}{l c c}
		Verteilung
			& $E(X)$
			& $Var(X)$ \\
		\hline
		& & \\
		$X \sim Hyp(n,r,s)$
			& $n \cdot \left(\frac{r}{N}\right)$
			& $n \cdot \left( 
				\frac{r}{N}
				\right) 
			\left( 
				1 - \frac{r}{N}
			\right)
			\left(
				\frac{(N)-n}{(N)-1}
			\right)$ \\
		& & \\
		$X \sim Bin(n,p)$
			& $n \cdot p$
			& $n \cdot p \cdot (1-p)$ \\
		& & \\
		$X \sim Pois(\lambda)$
			& $\lambda$
			& $\lambda$
	\end{tabular}
\end{table}

\subsection{Berechnungen in R}

\begin{table}[h!]
	\begin{tabular}{l l l}
	Hypergeometrisch & & \\ \hline
		& genau 	& \verb!dhyper(x=A,...)! \\
		& höchstens 	& \verb!phyper(q=A,...)! \\
		& mindestens 	& \verb!1-phyper(q=A-1,...)! \\
		& zufällig 	& \verb!rhyper(n=...)! \\
	& & \\
	Binomial & & \\ \hline
		& genau 	& \verb!dbinom(x=A,...)! \\
		& höchstens 	& \verb!pbinom(q=A,...)! \\
		& mindestens 	& \verb!1-pbinom(q=A-1,...)! \\
		& zufällig 	& \verb!rbinom(n=...)! \\
	& & \\
	Poisson & & \\ \hline
		& genau 	& \verb!dpois(x=A,...)! \\
		& höchstens 	& \verb!phyper(q=A,...)! \\
		& mindestens 	& \verb!1-ppois(q=A-1,...)! \\
		& zufällig 	& \verb!rpois(n=...)! \\
	\end{tabular}
\end{table}

\chapter{Stetige Verteilungen}
Stetige und absolut stetige Verteilungen beschreibebn Probleme, 
welche Ergebnisse aus $\mathbb{R}$ liefern.

\paragraph{Stetig} Die Eigenschaft der Stetigkeit ist so definiert,
dass die Punktwahrscheinlichkeit einer Zufallsvariable 
$X$ Null ergibt und $x$ auch wirklich jeden Wert aus
$\mathbb{R}$ annehmen kann.
\[ 
	P(X=x) = 0, \qquad x\in\mathbb{R}
\]
\paragraph{Absolute Stetigkeit}
Als absolut stetig werden Funktionen beschrieben die integrierbar 
sind. 

\newpage

\section{Dichtefunktion}
Die Dichtefunktion $f(x)$ ist definiert als die Ableitung der kummulativen
Verteilungsfunktion $F(x)$.
\[  
	\int f(x) := F(x) 
		\qquad 
		\Leftrightarrow 
		\qquad 
		f(x) = \frac{d}{dx} F(x)
		= F'(x)
\]
Mit der Dichte lässt sich eine Aussage darüber treffen, wie die 
Wahrscheinlichkeit ist, dass eine Zufallsvariable $X$ einen Wert
in einem bestimmten Intervall $[a,b]$ annimmt (siehe Grafik 
\ref{fig:dichte}).

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{dichtefunktion.pdf}
	\caption{Dichtefunktion $f(x)$ und kummulative Verteilungsfunktion 
		$F(x)$ in der Gegenüberstellung.}
	\label{fig:dichte}
\end{figure}

Mit der Definition der Dichtefunktion $f(x)$ lassen sich mehrere 
Gesetzmässigkeiten herleiten:
\begin{itemize}
	\item Die Dichte in einem Punkt $a$ ist Null.
		\[ f(x) = 0 
			\qquad \lim_{a_1 \rightarrow a_0} \left(
				\int_{a_0}^{a_1} f(x)\,dx \right) = 0   \]
	\item Das Integral einer Dichtefunktion über einem Intervall
		$[a,b]$ ist gleich der Differenz der kummulativen
		Wahrscheinlichkeiten von $a$ und $b$ (siehe Grafik 
		\ref{fig:dichte}).
		\[ \int_a^b f(X)\, dx = F(b) - F(a) \]
	\item Das Integral der Dichtefunktion über dem Intervall 
		$[-\infty, +\infty]$ ist genau 1 
		(siehe \gls{Axiome von Kolmogorov}, \gls{Normiertheit}).
		Dies bedeutet, dass die kummulative Verteilungsfunktion
		für grosse $x$ gegen $1$ strebt und für kleine gegen $0$.
		\[ \int_{-\infty}^{+\infty} f(x)\, dx = 1 \]
		\[ F(x) \xrightarrow{x \rightarrow +\infty} 1
			\qquad \Leftrightarrow \qquad 
			\lim_{x \rightarrow + \infty} 
				F(x) = 1 \]
		\[ F(x) \xrightarrow{x \rightarrow -\infty} 0 
			\qquad \Leftrightarrow \qquad
			\lim_{x \rightarrow - \infty} 
				F(x) = 0 \]
\end{itemize}

\subsection{Erwartungswert}
Der Erwartungswert einer stetigen Verteilung mit der Dichte $f(x)$ und 
der Funktion g(x) ist allgemein definiert als
\[ 
	E(g(X)) = \int_{-\infty}^{+\infty} g(x) \cdot f(x)\, dx
\]
Falls die Funktion $g(x)$ mit einer Variable gleichgesetzt werden
kann, also $g(x)=x$ gilt, dann kann der Erwartungswert auch berechnet
werden als
\[  
	E(X) = \int_{-\infty}^{+\infty} x \cdot f(x)\, dx,
		\qquad x = g(x)
\]

\subsection{Varianz}
\[ \begin{array}{l c l} 
	Var(X) 
		& = 
		& \displaystyle 
			\int_{-\infty}^{+\infty} 
			(x-E(X))^2 \cdot f(x)\, dx \\
		& & \\
		& = 
		& E(X-E(X))^2 \\
		& & \\
		& = 
		& E(X^2) - E(X)^2
\end{array} \]

\subsection{Standardabweichung}
Die Standardabweichung wird wie bei den diskreten Verteilungen 
duch die Wurzel aus der Varianz ermittelt.
\[  
	\sigma_x = \sqrt{Var(X)}
\]

\subsection{Quantile}
Ein Quantil $q(\alpha)$ markiert (in \%) die $x$-Stelle einer 
Dichtefunktion $f(x)$, bei welcher der angegebene Anteil $\alpha$
darunter liegt.
\[ 
	q(\alpha), 
		\qquad \alpha = 
		\{x \mid 0 < x < 1 \land x \in \mathbb{R}\}
\]
\[
	P(X \leq q(\alpha)) = \alpha
\]
\[ 
	F(q(\alpha)) = \alpha  
		\qquad \Leftrightarrow \qquad
		F^{-1}(\alpha) = q(\alpha)
\]

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{dichtefunktion-quantile.pdf}
	\caption{Quantil einer Dichtefunktion.}
	\label{fig:dichte-quantil}
\end{figure}

\clearpage
\newpage
\section{Uniforme Verteilung}

Die uniforme Verteilung (auch \emph{Gleichverteilung}) ist eine
Verteilung, deren Wahrscheinlichkeit nur in einem bestimmten 
Intervall $[a,b]$ ungleich Null ist. Die Dichte $f(x)$ innerhalb 
des Intervalls $[a,b]$ ist konstant und ausserhalb davon gleich Null.
Zusammenfassend kann man sagen, dass die uniforme Verteilung eine
konstante Dichte hat.

\[  
	f(x) = \mathrm{konstant} = \left\{\begin{array}{c c l}
		\displaystyle \frac{1}{b-a}
			& \text{falls}
			& a < x < b \\
		& & \\
		0
			& \text{falls}
			& (x < a) \lor (x > b)
		\end{array} \right.
\]

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{uniform.pdf}
	\caption{Uniforme Dichte $f(x)$ und Verteilung $F(x)$.}
	\label{fig:uniform}
\end{figure}

\subsection{Verteilungsfunktion}
Die Verteilungsfunktion der uniformen Verteilung beschreibt
grundsätlich eine Gerade und wenn das Intervall 
$[a,b]\neq[-\infty, +\infty]$ ist, so ist diese Bereichsweise
definiert.

\[  
	F(x) = \left\{
		\begin{array}{c c l}
			0 
				& \text{falls } 
				& x < a \\
			& \\
			\displaystyle
			\frac{x-a}{b-a} 
				& \text{falls } 
				& a < x < b \\
			& \\
			1
				& \text{falls } 
				& b < x
		\end{array} \right.
\]

\subsection{Erwartungswert}
Da die Dichtefunktion der uniformen Verteilung konstant ist,
kann der Erwartungswert sehr einfach berechnet werden.
\[  
	E(X) = \frac{a+b}{2}
\]
Die Werte $a,b$ können auch als Minimal- bzw. Maximalwerte
betrachtet werden.
\[  
E(X) = \frac{\text{min} + \text{max}}{2}
\]

\subsection{Varianz}
Analog zum Erwartungswert ist auch die Berechnung der Varianz
einer uniformen Verteilung relativ einfach.
\[ 
	Var(X) = \frac{(b - a)^2}{12}
\]
Wie auch beim Erwartungswert, können die Intervallgrenzen
$[a,b]$ als Mininal- und Maximalwerte betrachtet werden.
\[  
	Var(X) = \frac{(\text{max} - \text{min})^2}{12}
\]

\subsection{Verwendung in R}
\lstinline{R} stellt grundsätzlich vier Funktionen für die 
uniforme Verteilung zur Verfügung. 
\begin{itemize}
	\item \lstinline{dunif()} \hfill{} 
		(\emph{Wahrscheinlichkeitsverteilung})
	\item \lstinline{punif()} \hfill{}
		(\emph{kumulative Wahrscheinlichkeit})
	\item \lstinline{qunif()} \hfill{}
		(\emph{Verteilung der Quantile})
	\item \lstinline{runif()} \hfill{}
		(\emph{Zufallszahlen})
\end{itemize}
Die Abbildung \ref{fig:unif} zeigt jeweils einen Plot zu den gegebenen
Funktionen aus \lstinline{R}. Für weitere Informationen zu Plots siehe
Kapitel \ref{sec:plots}.

<<dunif, fig=FALSE, echo=FALSE>>=
plot(dunif(x=c(1:100), min=0, max=100), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(x)', xlab='Wert x', 
     main='dunif()')
@

<<punif, fig=FALSE, echo=FALSE>>=
plot(punif(q=c(1:100), min=0, max=100), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(X<=x)', xlab='Wert x', 
     main='punif()')
@

<<qunif, fig=FALSE, echo=FALSE>>=
plot(qunif(p=seq(from=0, to=1, by=0.001), min=0, max=100), type='l',
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='Wert x', 
     xlab='Quantil in Promille', main='qunif()')
@

<<runif, fig=FALSE, echo=FALSE>>=
plot(runif(n=100, min=0, max=100), cex.lab=1.5, cex.axis=1.5, 
     cex.main=1.5, cex.sub=1.5, ylab='Wert x', xlab='x-te Zahl', 
     main='runif()')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<dunif>>
@
\caption{Wahrscheinlichkeitsverteilung}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<punif>>
@
\caption{kumulative Wahrscheinlichkeit}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<qunif>>
@
\caption{Quantile}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<runif>>
@
\caption{Zufallszahlen}
\end{subfigure}
\caption{Uniforme Verteilung ($n=100, min=0, max=100$)}
\label{fig:unif}
\end{figure}

\clearpage
\subsection{Beispiel einer uniformen Verteilung}
Benutzt man einen ADC (engl. \emph{Analog to Digital Converter}) zur 
Erfassung elektronischer Messgrössen als digitale Werte, so 
\emph{quantifziert} dieser die Messung und es entsteht ein Messfehler. 
Ist die zu erfassende Grösse viel grösser als die kleinstmögliche 
Auflösung des ADC, so ist dieser Fehler uniform verteilt 
\parencite[615]{taoe}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.95\textwidth]{adc-system.pdf}
	\caption{Analog-to-Digital Converter, 8 Bit.}
\end{figure}

<<>>=
f1 <- 10*sin(x=seq(0, 2*pi, 0.001))
adc.in  <- (f1)
adc.out <- round(x=adc.in, digits=0)
error   <- (adc.in - adc.out)
m <-mean(error)
s <-sd(error)
m
s
@

\noindent
Mit Hilfe von R lässt sich dieses Beispiel relativ leicht rechnen und
plotten. Die Plots aus der Abbildung \ref{fig:adc} zeigen, dass die 
Quantifizireung des Eingangsignal einen uniformen Fehler verusrsacht.
Die Grafik \ref{fig:adc-d} zeigt den Beweis für die uniforme Verteilung
anhand eines Quantilenvergleichs mit einer ideal uniform verteilten
Datenreihe.

<<adc1, fig=FALSE, echo=FALSE>>=
f1 <- 10*sin(x=seq(0, 2*pi, 0.001))
adc.in <- (f1)
adc.out <- round(adc.in, digits=0)
error <- adc.in - adc.out
plot(adc.in, type='l', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, 
     cex.sub=1.5, ylab='Spannung', xlab='Zeit', main='ADC Eingabe')
@

<<adc2, fig=FALSE, echo=FALSE>>=
f1 <- 10*sin(x=seq(0, 2*pi, 0.001))
adc.in <- (f1)
adc.out <- round(adc.in, digits=0)
error <- adc.in - adc.out
plot(adc.out, type='l', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, 
     cex.sub=1.5, ylab='Spannung', xlab='Zeit', main='ADC Ausgabe')
@

<<adc3, fig=FALSE, echo=FALSE>>=
f1 <- 10*sin(x=seq(0, 2*pi, 0.001))
adc.in <- (f1)
adc.out <- round(adc.in, digits=0)
error <- (adc.in-adc.out)
plot(error, type='h', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, 
     cex.sub=1.5, ylab='Spannung', xlab='Zeit', ylim=c(-2,2), main='Messfehler')
@

<<adc4, fig=FALSE, echo=FALSE>>=
f1 <- 10*sin(x=seq(0, 2*pi, 0.001))
adc.in <- (f1)
adc.out <- round(adc.in, digits=0)
error <- (adc.in-adc.out)
error <- sort(error)
check <- runif(n=1000)
qqplot(check, error, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, 
       cex.sub=1.5, ylab='Quantile Uniform', xlab='Quantile Fehler', main='QQ-Plot')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<adc1>>
@
\caption{Eingangssignal $u_e(t)\in\mathbb{R}$}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<adc2>>
@
\caption{Digitalisierung $(\mathbb{R} \rightarrow 2^n, n\in \mathbb{N})$}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<adc3>>
@
\caption{Fehler $u_a(t)$}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<adc4>>
@
\caption{Quantilenvergleich mit $\mathcal{U}(a,b)$}
\label{fig:adc-d}
\end{subfigure}
\caption{Quantifizierungfehler eines ADC.}
\label{fig:adc}
\end{figure}

\newpage
\section{Normalverteilung}
Die Normalverteilung (auch \emph{Gauss-Verteilung} bzw. 
\emph{Gauss'sche Glockenkurve}) ist eine bedeutende stetige
Verteilung für sämtliche Bereiche der Natur- und 
Ingenieurwissenschaften. Der sog. \emph{Zentrale Grenzwertsatz}
macht sie zu einer der wichtigsten Verteilungen überhaupt
\parencite[297]{henze}. 


\[ 
	f(x) = \frac{1}{\sigma\sqrt{2\pi}}\cdot e^{
		\left( -\frac{(x-\mu)^2}{2\sigma^2} \right)}
\]

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{normal.pdf}
	\caption{Normalverteilung}
	\label{fig:normal}
\end{figure}

\noindent
Der Zentrale Grenzwertsatz besagt,
dass ein Stichprobenmittelwert $\overline{x}$ für grosse
Stichproben annähernd normalverteilt ist mit 
$\overline{X}\sim\mathcal{N}(\mu, \frac{\sigma^2}{n})$ 
wobei der kritische Stichprobenumfang bei ca. 30 Stichproben
liegt \parencite[481]{oreilly}.


Die Interpretation der Normalverteilung 
$X \sim \mathcal{N}(\mu, \sigma^2)$
ist sehr anschaulich durch deren Parameter. Der Mittelwert 
$\mu$ zeigt das Zentrum der \emph{Glockenkurve} an, wo auch die 
Wahrscheinlichkeit am höchsten ist. Die Varianz zeigt an, wie 
flach die \emph{Glockenkurve} ist. 

Ein Spezialfall der Normalverteilung ist die sog.
\emph{standardisierte Normalverteilung}, welche einen 
Erwartungswert $\mu=0$ und eine Varianz $\sigma^2=1$ hat.
Mittels dieser lassen sich Ergebnisse beliebig transformieren
\parencite[298]{henze}.


\subsection{Verteilungsfunktion}

\subsection{Erwartungswert}
Der Erwartungswert einer Normalverteilung beschreibt jene
Stelle $x$ bei der die \emph{Glockenkurve} am höchsten ist.
Dieser Wert ist zugleich auch ein Parameter der Dichtefunktion
der Normalverteilung.
\[  
	E(X) = \mu
\]

\subsection{Varianz}
Die Varianz einer Normalverteilung ist wie der Erwartungswert
$\mu$ gleich eine Parameter der Dichtefunktion und beschreibt
wie flach die \emph{Glockenkurve} ist.
\[  
	Var(X) = \sigma^2
\]

\subsection{Verwendung in R}
\lstinline{R} stellt grundsätzlich vier Funktionen für die 
Normalverteilung zur Verfügung. 
\begin{itemize}
	\item \lstinline{dnorm()} \hfill{} 
		(\emph{Wahrscheinlichkeitsverteilung})
	\item \lstinline{pnorm()} \hfill{}
		(\emph{kumulative Wahrscheinlichkeit})
	\item \lstinline{qnorm()} \hfill{}
		(\emph{Verteilung der Quantile})
	\item \lstinline{rnorm()} \hfill{}
		(\emph{Zufallszahlen})
\end{itemize}
Die Abbildung \ref{fig:norm} zeigt jeweils einen Plot zu den gegebenen
Funktionen aus \lstinline{R}. Für weitere Informationen zu Plots siehe
Kapitel \ref{sec:plots}.

<<dnorm, fig=FALSE, echo=FALSE>>=
plot(dnorm(x=c(1:100), mean=50, sd=10), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(x)', xlab='Wert x', 
     main='dnorm()')
@

<<pnorm, fig=FALSE, echo=FALSE>>=
plot(pnorm(q=c(1:100), mean=50, sd=10), type='l', cex.lab=1.5, 
     cex.axis=1.5, cex.main=1.5, cex.sub=1.5, 
     ylab='P(X<=x)', xlab='Wert x', 
     main='pnorm()')
@

<<qnorm, fig=FALSE, echo=FALSE>>=
plot(qnorm(p=seq(from=0, to=1, by=0.001), mean=50, sd=10), type='l',
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, ylab='Wert x', 
     xlab='Quantil in Promille', main='qnorm()')
@

<<rnorm, fig=FALSE, echo=FALSE>>=
plot(rnorm(n=100, mean=50, sd=10), cex.lab=1.5, cex.axis=1.5, 
     cex.main=1.5, cex.sub=1.5, ylab='Wert x', xlab='x-te Zahl', 
     main='rnorm()')
@

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<dnorm>>
@
\caption{Wahrscheinlichkeitsverteilung}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<pnorm>>
@
\caption{kumulative Wahrscheinlichkeit}
\end{subfigure}

\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<qnorm>>
@
\caption{Quantile}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
<<fig=TRUE, echo=FALSE>>=
<<rnorm>>
@
\caption{Zufallszahlen}
\end{subfigure}
\caption{Normalverteilung ($\mu=50, \sigma^2=10$)}
\label{fig:norm}
\end{figure}

\clearpage

\subsection{Beispiel einer Normalverteilung}
Bei digitalen Übertragungen entsteht durch diverse Umwelteinflüsse 
ein sog. \emph{Jitter}. Dieser beschreibt ein variieren der 
Taktzeiten einer Übertragung. Ein Teil des gesamten Jitters bildet 
der sogenannte \emph{zufällige Jitter} welcher Normalverteilt ist.
D.h. die zeitliche Grenze eines Zyklus folgt einer bestimmten
Verteilung, wobei die Ränder dieser Grenzen normalverteilt abweichen.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{jitter.pdf}
	\caption{Zufalls-Jitter}
	\label{fig:jitter}
\end{figure}

\newpage
\section{Exponentialverteilung}
\subsection{Verteilungsfunktion}
\subsection{Erwartungswert}
\subsection{Varianz}
\subsection{Verwendung in R}
\subsection{Beispiel einer Exponentialverteilung}

\newpage
\section{Zusammenfassung}
\paragraph{Uniforme Verteilung}
\[ X \sim \mathcal{U}(a,b) \]
\[ \begin{array}{l c l}
	F(X) 
		& =
		& \displaystyle \frac{x-a}{b-a} \\
	f(x)	
		& =
		& \displaystyle \frac{1}{b-a}  \\
	D_f	
		& = 
		& a < x < b \\
	E(X)
		& = 
		& \displaystyle \frac{a+b}{2}\\
	Var(X)	
		& =
		& \displaystyle \frac{(b-a)^2}{12}\\
\end{array} \]

\paragraph{Normalverteilung}
\[ X \sim \mathcal{N}(\mu, \sigma^2) \]
\[ \begin{array}{l c l}
	F(X) 
		& =
		& \displaystyle \frac{x-a}{b-a} \\
	f(x)	
		& =
		& \displaystyle \frac{1}{\sigma\sqrt{2\pi}} \cdot
				e^{\left(
					-\frac{(x-\mu)^2}{2\sigma^2}
				\right)} \\
	D_f	
		& = 
		& x \in \mathbb{R} \\
	E(X)
		& = 
		& \mu\\
	Var(X)	
		& =
		& \sigma^2 \\
\end{array} \]

\paragraph{Exponentialverteilung}
\[ X \sim Exp(\lambda) \]
\[ \begin{array}{l c l}
	F(X) 
		& =
		& F(X) = \displaystyle \frac{x-a}{b-a} \\
	f(x)	
		& =
		& \displaystyle \lambda \cdot 
				e^{\left(
					-\lambda x
				\right)} \\
	D_f	
		& = 
		& x > 0 \\
	E(X)
		& = 
		& \displaystyle \frac{a+b}{2}\\
	Var(X)	
		& =
		& \displaystyle \frac{(b-a)^2}{12}\\
\end{array} \]


\subsection{Berechnungen in R}
